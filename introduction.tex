
\section{Introduction}

The design of an embedded system requires different conflicting
objectives (energy consumption, performance, area) to be fulfilled.
Several factors are involved in this goal and real cases show how
often no analytical results are known to predict the relation between
system configurations and objectives. In such cases an high level
system simulation is the only way to have a picture of how system
parameters impact on the objectives.  The key problem is that the size
of the design space to be simulated grows with the product of
cardinalities of parameters, easily yelding an untractable number
of simulations. In order to address such task a ``Design Space
Exploration'' strategy is required, i.e. a methodology to evaluate
only a small subset of all possible configurations while maintaining a
good level of efficiency and accuracy.

The final result of every design space exploration is a subset of the
configurations called Pareto Set (\cite{pareto}). Roughly speaking, it
is a set of configurations representing the trade-offs between
objectives: for each of configuration of the Pareto Set there is no
other configuration performing better for all the objectives
considered. Of course this is an high level estimation so in a
subsequent step of the design flow these few promising configurations
can be more accurately evaluated using detailed low level simulations.

In this work we present PS, a multiobjective design exploration
strategy which introduce the concept of Parameter Space representation
of Pareto Set. The main idea is to ....

Many exploration algorithms form the resulting Pareto set in an incremental
way. The algorithm adds and removes configurations in Pareto set while
choosing the configurations to evaluate and simulating them. So Pareto
set ``evolves'' towards the final one. The dynamical view of the
Pareto set shaping can be seen as the ``behavior'' of the algorithm.
This behavior tells us how the Pareto set ``converges'' towards
the final Pareto set. 

\section{\label{sec:Related-work}Related work}
% TODO: short, remove descriptions
% SPEA2 as choice, comparison of it agains other GA is available 

Many different design space exploration algorithms have been proposed.
A design space exploration algorithm is typically not based on precise
/ analytical / mathematical evidences. The motivations of an exploration
algorithm are rather heuristic, have some form of arbitrariness and,
to a large extend, intuition lies behind them.

The ``Dependency analysis'' proposed in \cite{givargis_tvlsi02}, is meant
to take advantage of the dependency among the parameters in a multiobjective
optimization problem. It is required that the designer knows, prior
to the exploration, if a parameter X is dependent from a parameter
Y, i.e. changing the value of Y ``impacts the optimal parameter value''
for X. With this a-priori knowledge, the designer can construct a
``dependency graph'' and recognize clusters, i.e. subsets of strongly
dependency-connected parameters. Each cluster is exhaustively evaluated
and its ``local Pareto set'' is found. Then, all local Pareto sets
are merged. Doing this way, a ``sum'' of local exhaustive evaluations
are performed instead of an exhaustive evaluation of all the possible
configurations. Some problems arise: i) In real scenarios, it may
be very difficult to recognize really independent clusters of parameters,
because there may be interdependencies among a very large number of
parameters. This may lead to the need of an exhaustive search through
almost all the possible configurations. ii) A designer may not have
a precise and complete picture of the dependencies among parameters;
for this reason the need of ``automated approaches for computing
{[}...{]} interdependencies'' is declared in the same paper. iii)
There may be some ``local dependencies'', i.e. dependencies that
emerge only if parameter values are bounded to certain ranges.

These drawbacks are not present in our solution. The algorithm presented
here is also meant to take advantage of dependency but is not directly
based on dependency itself, but rather it ``catches'' dependencies
in terms of ``interesting or uninteresting regions''; as a consequence
no a-priori knowledge of dependencies is required as they are discovered
during exploration. Moreover, recognizing regions offers the capability
to capture local dependencies.

Abraham, Rau and Schreiber proposed in \cite{santosh_hptr00} to decompose
the system to be evaluated into components that interact minimally
with each other. ``Alternative designs for each component are evaluated
in isolation to determine the best designs for individual components.
Combinations of these designs are then put together to build the complete
system design''. Pareto sets for each component are found and, provided
that ``monotonicity'' exists, the complete Pareto set is computed
merging the component Pareto sets. Roughly speaking (see section 4
of the same paper for more details), monotonicity property guarantees
that the best system can be obtained as a composition of the best
components. This approach would perfectly work if all the components
were perfectly isolated, i.e., if there were no dependencies among
different components (in a sense similar (but not necesarily equal)
to the one of Dependency analisys). But real scenarios seldom if ever
expose monotonicity property. This leads to some ``inaccuracies''
(as stated in section 4.6.1 of the same paper).

Other approaches take into account the concept of ``sensitivity''.
The sensitivity of an objective with the respect to a parameter is
a measure of how much the objective varies when varying that parameter.
A ``sensitivity analysis'' was used in \cite{fornaciari_codes01} in an optimization
problem with only one objective (the power-delay product of an electronic
device). This method was extended in \cite{palesi_iwsoc02} to a multiobjective
optimization. In that work the sensitivity of objectives with
the respect to each parameter is measured, and parameters are ordered
on the base on these sensitivity measures. Then, a first Pareto set
is obtained varying the first parameter, having fixed to arbitrary
values all other parameters. The Pareto set is then refined varying,
in a similar way, the other parameters, one by one. Experimental results
(see section 4.2 of the same work) show that this method is not of
good ``quality'' (as broadly defined in the introduction). The reason
can be found in the very limited and rigid exploration of the parameter
space: after computing the first Pareto set, there are no more chances
to consider configurations with values of the first parameter other
than the ones assumed in the first Pareto set calculation. Similar
limitations are imposed after computing the second Pareto set, the
third and so on. It is worth noticing that this approach can not capture
``local sensitivity'' (this drawback will be called ``local sensitivity
limitation''), i.e. the objectives may be more sensitive to some
ranges of a parameter and less sensitive to other ranges of the same
parameter. Moreover it can not capture ``combined sensitivity''
(``combined sensitivity limitation''), i.e. the objectives may be
more sensitive to a range of a parameter $p_{1}$, only when other
parameters are within certain ranges, and less sensitive to the same
range of parameter $p_{1}$ when the other parameters are not within
those ranges. Therefore, in the method we propose, we do not use the
sensitivity directly, but we use the concept of innovation (that can
be considered, at least weakly related to the sensitivity). We do
not measure innovation of a parameter (as done for the sensitivity),
but rather we measure the innovation of a ``region'' of parameter
space, in order to overcome both the ``local sensitivity limitation''
and the ``combined sensitivity limitation'' stated above for the
sensitivity analysis.

Many studies focus on genetic approaches to resolve multiobjective
optimization problems (\cite{} and others). Genetic approaches
have many advantages: they have proved good quality (as broadly defined
in the introduction), they are customizable, they are very general
and require no a-priori knowledge to the designer. Genetic algorithms
run in subsequent iterations. Configurations are represented as chromosomes.
In each iteration a ``population'' of configurations is evaluated.
Some configurations are discarded. Each selected configuration is
combined with the preceding population and then ``mutated'' (i.e.
the resulting configuration is varied a little). Iterating this operations,
populations are expected to become ``better and better''. The strong
point of genetic approaches can be summarized saying that they consist
in a broad exploration (the mutation permits to make the exploration
not rigidly restricted to limited parts of parameter space), although
this exploration is not random but is guided by the performances of
the already evaluated configurations. Therefore, the exploration is
neither too much constrained nor too much random. We claim that the
approach presented in this paper has all the benefits of the genetic
approaches, although the rational is completely different.
