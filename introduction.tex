
\section{Introduction and Motivation}

The design of an embedded system requires different conflicting
objectives (energy consumption, performance, area) to be fulfilled.
Several factors are involved in this goal and real cases show how
often no analytical results are known to predict the relation between
system configurations and objectives. In such cases an high level
system simulation is often the only way to have a picture of how system
parameters impact on the objectives.  A key problem is that the size
of the design space to be simulated grows with the product of
cardinalities of each parameter, easily resulting in an untractable number
of simulations. In these cases a ``Design Space
Exploration'' strategy is required, i.e. a methodology to evaluate
only a small subset of all possible configurations while maintaining a
good level of efficiency and accuracy~\cite{surviving_soc}.

The final result of a design space exploration is a subset of the
configurations called Pareto Set (\cite{pareto}) (See also Definition
\ref{pers02.def:Pareto-set}. It represents the trade-offs between
objectives, so that for each of configuration of the Pareto Set there is no
other configuration performing better for all the objectives
considered. Once these few promising configurations have been obtained, a
subsequent step of the design flow can eventually afford a more
accurate low level simulation.

In this work we present PS, a multiobjective design exploration
strategy that introduces the concept of Parameter Space Representation
of Pareto Set. The main idea is focusing on the ``innovation''
introduced in the Pareto sets and then accordingly distribuiting the
exploration effort in regions created in the multidimensional space of
system parameters.

Many different design space exploration algorithms have been proposed
in literature.  The motivations of an exploration
algorithm are rather heuristic, have some form of arbitrariness and,
to a large extend, intuition lies behind them.

Some exploration strategies assume some kind of ``knowledge'' about
the system parameters, their meaning and impact on design objectives.
The ``Dependency analysis'' proposed in \cite{givargis_tvlsi02}, is meant
to take advantage of the dependency among the parameters in a multiobjective
optimization problem.  With this a-priori knowledge, the designer can construct a
``dependency graph'' and recognize clusters, i.e. subsets of strongly
dependency-connected parameters. Each cluster is exhaustively evaluated
and its ``local Pareto set'' is found. Then, all local Pareto sets
are merged. Doing this way, a ``sum'' of local exhaustive evaluations
are performed instead of an exhaustive evaluation of all the possible
configurations. Some problems arise: i) In real scenarios, it may
be very difficult to recognize really independent clusters of parameters,
because there may be interdependencies among a very large number of
parameters. This may lead to the need of an exhaustive search through
almost all the possible configurations. ii) A designer may not have
a precise and complete picture of the dependencies among parameters;
for this reason the need of ``automated approaches for computing interdependencies'' is declared in the same paper. 
These drawbacks are not present in our contribution. The algorithm presented
here is also meant to take advantage of dependency but is not directly
based on dependency itself, but rather it ``catches'' dependencies
in terms of ``interesting or uninteresting regions''; as a consequence
no a-priori knowledge of dependencies is required as they are discovered
during exploration. Moreover, recognizing regions offers the capability
to capture local dependencies,  i.e. dependencies that
emerge only if parameter values are bounded to certain ranges.


Abraham, Rau and Schreiber proposed in \cite{santosh_hptr00} to decompose
the system to be evaluated into components that interact minimally
with each other. Pareto sets for each component are found and, provided
that ``monotonicity'' exists, the complete Pareto set is computed
merging the component Pareto sets. Roughly speaking (see section 4
of the same paper for more details), monotonicity property guarantees
that the best system can be obtained as a composition of the best
components. This approach would perfectly work if all the components
were perfectly isolated, i.e., if there were no dependencies among
different components (in a sense similar (but not necesarily equal)
to the one of Dependency analisys). But real scenarios seldom if ever
expose monotonicity property. This leads to some ``inaccuracies''
(as stated in section 4.6.1 of the same paper).

Other approaches take into account the concept of ``sensitivity''.
The sensitivity of an objective with the respect to a parameter is
a measure of how much the objective varies when varying that parameter.
A ``sensitivity analysis'' was used in \cite{fornaciari_codes01} in an optimization
problem with only one objective (the power-delay product of an electronic
device). This method was extended in \cite{palesi_iwsoc02} to a multiobjective
optimization. In that work the sensitivity of objectives with
the respect to each parameter is measured, and parameters are ordered
on the base on these sensitivity measures. Then, a first Pareto set
is obtained varying the first parameter, having fixed to arbitrary
values all other parameters. The Pareto set is then refined varying,
in a similar way, the other parameters, one by one. Experimental results
(see section 4.2 of the same work) show that this method is not of
good ``quality'' (as broadly defined in the introduction). The reason
can be found in the very limited and rigid exploration of the parameter
space: after computing the first Pareto set, there are no more chances
to consider configurations with values of the first parameter other
than the ones assumed in the first Pareto set calculation. Similar
limitations are imposed after computing the second Pareto set, the
third and so on. It is worth noticing that this approach can not capture
``local sensitivity'' (this drawback will be called ``local sensitivity
limitation''), i.e. the objectives may be more sensitive to some
ranges of a parameter and less sensitive to other ranges of the same
parameter. Moreover it can not capture ``combined sensitivity''
(``combined sensitivity limitation''), i.e. the objectives may be
more sensitive to a range of a parameter $p_{1}$, only when other
parameters are within certain ranges, and less sensitive to the same
range of parameter $p_{1}$ when the other parameters are not within
those ranges. Therefore, in the method we propose, we do not use the
sensitivity directly, but we use the concept of innovation (that can
be considered, at least weakly related to the sensitivity). We do
not measure innovation of a parameter (as done for the sensitivity),
but rather we measure the innovation of a ``region'' of parameter
space, in order to overcome both the ``local sensitivity limitation''
and the ``combined sensitivity limitation'' stated above for the
sensitivity analysis.

Many studies focus on genetic approaches to resolve multiobjective
optimization problems (\cite{coello_easmop} and others). Genetic approaches
have many advantages: they have proved good quality (as broadly defined
in the introduction), they are customizable, they are very general
and require no a-priori knowledge to the designer.  The strong
point of genetic approaches can be summarized saying that they consist
in a broad exploration (the mutation permits to make the exploration
not rigidly restricted to limited parts of parameter space), although
this exploration is not random but is guided by the performances of
the already evaluated configurations. Therefore, the exploration is
neither too much constrained nor too much random. We claim that the
approach presented in this paper has most of the benefits of the genetic
approaches, although the rational is completely different.

The paper is organized as follows: in
Section~\ref{sec:statement_of_the_problem} we formally introduce the
main concepts and the definitions required to apply the proposed strategy. Next in
Section~\ref{sec:algorithm} we present the PS algorithm in detail.
Finally in Section~\ref{sec:ee} we show a case study involving the
exploration of the hardware/software parameters of a VLIW
architecture, performing a qualitative and quantitative comparison of
PS agains the state-of-art of multiobjective genetic based approaches.
